\documentclass[onecolumn, draftclsnofoot,10pt, compsoc]{IEEEtran}
\usepackage{graphicx}
\usepackage{url}
\usepackage{setspace}
\graphicspath{ {images/} }

\usepackage{geometry}
\geometry{textheight=9.5in, textwidth=7in}

\def \CapstoneTeamName{		Look Boss, No Hands}
\def \CapstoneTeamNumber{		9}
\def \GroupMemberOne{			Brandon Dring}
\def \GroupMemberTwo{			Nipun Bathini}
\def \GroupMemberThree{			Carl Benson}
\def \CapstoneProjectName{		CDK Global: No more touch. No more Keyboard. Bring it All Together. Using Technology to Teach Humans.}
\def \CapstoneSponsorCompany{	CDK Global}
\def \CapstoneSponsorPerson{		Trevor moore}


\def \DocType{Problem Statement}

\newcommand{\NameSigPair}[1]{\par
\makebox[2.75in][r]{#1} \hfil 	\makebox[3.25in]{\makebox[2.25in]{\hrulefill} \hfill		\makebox[.75in]{\hrulefill}}
\par\vspace{-12pt} \textit{\tiny\noindent
\makebox[2.75in]{} \hfil		\makebox[3.25in]{\makebox[2.25in][r]{Signature} \hfill	\makebox[.75in][r]{Date}}}}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{document}
\begin{titlepage}
    \pagenumbering{gobble}
    \begin{singlespace}
        \hfill
        \par\vspace{.2in}
        \centering
        \scshape{
            \huge CS Senior Capstone \DocType \par
            {\large October 8th, 2017, Fall 2017}\par
            \vspace{.5in}
            \textbf{\Huge\CapstoneProjectName}\par
            \vspace{.5in}
            \includegraphics[height=4cm]{Team-Logo}
            \vfill
            {\large Prepared for}\par
            \Huge \CapstoneSponsorCompany\par
            \vspace{5pt}
            {\Large\NameSigPair{\CapstoneSponsorPerson}\par}
            {\large Prepared by }\par
            Group\CapstoneTeamNumber\par
            % 5. comment out the line below this one if you do not wish to name your team
            \CapstoneTeamName\par
            \vspace{5pt}
            {\Large
                \NameSigPair{\GroupMemberOne}\par
                \NameSigPair{\GroupMemberTwo}\par
                \NameSigPair{\GroupMemberThree}\par
            }
            \vspace{20pt}
        }
        \begin{abstract}
        % 6. Fill in your abstract
        With the ever increasing technologies that relate to how humans interact with computers, there are now countless new way to get data. From the integration of Virtual Reality being able to immerse the user in a new environment, tracking the user’s vitals, receiving data from your wrist by wearables, or issuing commands to a virtual personal assistant. This project aims at mixing all of them together to create a new novel experience. Being able to ask your personal assistant “Alexa, tell me Subaru’s sales data in America last week”. Then, having the command register and populate the VR headset with the data, while tracking them via the wearable to monitor how they are experiencing the data. By putting the user in a 3D virtual environment, populated by voice commands they can work with the data with their own hands, and experience it in a whole new way.


        \end{abstract}
    \end{singlespace}
\end{titlepage}
\newpage
\pagenumbering{arabic}
\tableofcontents
\clearpage

% 8. now you write!
\section{Description}
There are many new technologies emerging as of late, and with those technologies come new ways to experience them. In 2007, Fitbit broke new ground by prototyping the first wearable that integrates with your phone, receiving notifications, and counting steps. In 2012, the Oculus Rift made waves in the tech community bringing Virtual Reality to the masses. And in 2014 Amazon had released their very own voice activated personal assistant, Alexa. While all these devices are groundbreaking on their own, no one has integrated them together into one cohesive functioning unit. Furthermore, no one has really done anything commercially successful with VR besides video games. This project aims to solve that, merging them all together to build something new on the innovative technology stage that individually all these products had helped create.

Being able to request for example sales data at your company with your voice; then, having it populate the virtual world you are currently in with data you can see and almost feel. Allowing the ability to overlay, and move the data around to experience it in a whole new way; instead of searching through a computer and displaying it on a screen. Then, with a wearable, it could also track the heart rate; using machine learning it could figure out when the user is shocked by viewing some data. Later, alerting them when the numbers in the future start to trend higher or lower to prepare the user for the next experience. CDK Global has hopes of putting something like this in their lobby for clients to be able to experience their own sales data, or reporting in a whole new way.

So, the scope of the problem is broken down into 3 main parts: having Alexa register a custom personal command, populating a VR environment with the request, and having a wearable monitor and learn their heart rate as they are taken through the experience.


\section {Solution}
To start with, for a VR solution we will most likely settle on using an HTC Vive, due to the development environment being relatively friendly, economical, and possessing a large market share. Learning how the motion is displayed from within the headset, and how the controllers that come with it interact with the displayed screen. For the voice processing, Amazon Alexa seems to fit our needs well. Our client says that CDK already has all the development set up done. We simply just need the credentials to log in before being able to personalize commands. Plus, using the Alexa when deploying it doesn’t have to be thoroughly reviewed by Apple which might become a blocker later on. The use of the Alexa is dependant on learning how the device interprets speech and processes it and maps it into a command. Then for the wearable probably a Fitbit, again since their developer environment isn’t as strict like Apple. Here the largest problem is learning how the device records and monitors the heart rate data it obtains, and having a method to store it.

Amazon has released a developer SDK in which they allow development of their Alexas. We can register for one of the accounts under CDK Global, following Amazon’s guides on how to map custom commands to their device.

The HTC Vive is largely based on the Unity framework, which is solely based on the C\# programming language. Then learning the C\# language, and the HTC Vive SDK, understand how to populate a VR environment and being able to interact with it.

We would also need to create an app for the Fitbit whose SDK is based in javascript, and follow their guides to constantly monitor the heart rate of the user. And whenever a command is issued, the wearable sets a marker to know what data the user is observing. The wearable should then send the marker to a server about what data was on the screen when the user’s heart rate had spiked. Creating a profile on every user in the database, should map custom thresholds about what data the user was observing, and what the numbers of that data were shown when they reacted.

The main challenge would be to get the Amazon Alexa and the VR to work in tandem. After a Google search, it looks as if a young developer has already integrated Alexa to work with their VR system, better yet they had posted a guide on how they did it online. We should then route the command to hook up with a PC to run the program to display data to the VR headset.



Finally, there would need to be a server process running monitoring the data that the user was looking at and observing the numbers. If the numbers get too high or low on the dataset then the user can get a notification via email, text or whatever they choose.

\newpage

\section{Done When}

As the client stated (Trevor Moore), the project has hit the minimum deliverable when the first voice command has been issued and populated the VR headset appropriately. While new commands and environments/functionality can simply be added by plugins or some simple additions to the code. If we have the time, that is when the wearables come together with the monitoring, machine learning, and notifications.


\section{Performance Metrics}
To gauge performance and success we will hold these values:
\begin{itemize}

\item Regular contact with the client, to ask questions, via IM or emails. Updating them weekly about any new progress that has been made, what is planned to be done, and any blockers for the planned progress.

\item Adoption of an agile like system to track progress and be kept up to date. Seeing what needs to be done, what’s being worked on, what has been done.

\item Daily contact with each other on the capstone team via IM. At least a weekly personal face to face meeting to work on the project together.

\item Having a space to test the voice processing, virtual reality, and wearables in one spot.

\item A schedule to ensure that everyone has a chance with the hardware to test any new changes they’ve added.

\item Creating a suite of unit tests to the project such that any refactoring must pass the same set of tests that ensure functionality is still present.

\item Using continuous integration (Travis CI), to ensure any feature or functionality added to the project is tested before being added.

\item All proper hardware needed for the project should be acquired, setup, and usable by the end of the Fall term.

\item Synchronizing the Amazon Alexa and the virtual reality headset to process commands such as ‘Alexa, show me Ford’s sales data for 2016’. Then having Alexa process that command, and populate the headset with some data visualization of the request.

\item The time it takes to get into a proper virtual reality system, ready to interact with the program should be no more than just putting on the headset and asking questions to Alexa.

\item Adding new commands to be recognized by the personal assistant should take no more than an hour.

\item The time it takes to ask Alexa a question, and being able to see it in virtual reality should take 5 - 10 seconds.

\item The user should be able to use the VR controllers to point and drag the data sets/visualizations around and interact with them.

\item Wearables will properly report what the user’s heart rate is while being in virtual reality. Sending data to the server, monitoring the data sets that were reacted upon and sending out notifications whenever a certain user’s reaction meet a threshold number.

\item Everything should be synchronized in which the Amazon Alexa, virtual reality headset, and Fitbit should be monitoring the user.

\item The wearable should know what data is being looked at by the user in VR, as synchronized by the Alexa command.
\end{itemize}

\end{document}
